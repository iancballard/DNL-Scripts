{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start ipcluster controller\n",
    "from ipyparallel import Client\n",
    "rc = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TR = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mask(d, raw_d=None, nskip=3, mask_bad_end_vols=True):\n",
    "    mn = d[:,:,:,nskip:].mean(3)\n",
    "    masked_data, mask = median_otsu(mn, 3, 2)\n",
    "    mask = np.concatenate((np.tile(True, (d.shape[0], d.shape[1], d.shape[2], nskip)),\n",
    "                           np.tile(np.expand_dims(mask==False, 3), (1,1,1,d.shape[3]-nskip))),\n",
    "                           axis=3)\n",
    "    if mask_bad_end_vols:\n",
    "        # Some runs have corrupt volumes at the end (e.g., mux scans that are stopped prematurely). Mask those too.\n",
    "        # But... motion correction might have interpolated the empty slices such that they aren't exactly zero.\n",
    "        # So use the raw data to find these bad volumes.\n",
    "        # 2015.10.29 RFD: this caused problems with some non-mux EPI scans that (inexplicably)\n",
    "        # have empty slices at the top of the brain. So we'll disable it for now.\n",
    "        if raw_d!=None:\n",
    "            slice_max = raw_d.max(0).max(0)\n",
    "        else:\n",
    "            slice_max = d.max(0).max(0)\n",
    "        bad = np.any(slice_max==0, axis=0)\n",
    "        # We don't want to miss a bad volume somewhere in the middle, as that could be a valid artifact.\n",
    "        # So, only mask bad vols that are contiguous to the end.\n",
    "        mask_vols = np.array([np.all(bad[i:]) for i in range(bad.shape[0])])\n",
    "    # Mask out the skip volumes at the beginning\n",
    "    mask_vols[0:nskip] = True\n",
    "    mask[:,:,:,mask_vols] = True\n",
    "    brain = np.ma.masked_array(d, mask=mask)\n",
    "    good_vols = np.logical_not(mask_vols)\n",
    "    return brain,good_vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_motion(nifti_image):\n",
    "    # BEGIN STDOUT SUPRESSION\n",
    "    actualstdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull,'w')\n",
    "    # We want to use the middle time point as the reference. But the algorithm does't allow that, so fake it.\n",
    "    ref_vol = nifti_image.shape[3]/2 + 1\n",
    "    ims = nb.four_to_three(nifti_image)\n",
    "    reg = Realign4d(nb.concat_images([ims[ref_vol]] + ims),tr=TR) # in the next release, we'll need to add tr=1.\n",
    "\n",
    "    reg.estimate(loops=3) # default: loops=5\n",
    "    aligned = reg.resample(0)[:,:,:,1:]\n",
    "    sys.stdout = actualstdout\n",
    "    # END STDOUT SUPRESSION\n",
    "    abs_disp = []\n",
    "    rel_disp = []\n",
    "    transrot = []\n",
    "    prev_T = None\n",
    "    # skip the first one, since it's the reference volume\n",
    "    for T in reg._transforms[0][1:]:\n",
    "        # get the full affine for this volume by pre-multiplying by the reference affine\n",
    "        #mc_affine = np.dot(ni.get_affine(), T.as_affine())\n",
    "        transrot.append(T.translation.tolist()+T.rotation.tolist())\n",
    "        # Compute the mean displacement\n",
    "        # See http://www.fmrib.ox.ac.uk/analysis/techrep/tr99mj1/tr99mj1/node5.html\n",
    "        # radius of the spherical head assumption (in mm):\n",
    "        R = 80.\n",
    "        # The center of the volume. Assume 0,0,0 in world coordinates.\n",
    "        # Note: it might be better to use the center of mass of the brain mask.\n",
    "        xc = np.matrix((0,0,0)).T\n",
    "        T_error = T.as_affine() - np.eye(4)\n",
    "        A = np.matrix(T_error[0:3,0:3])\n",
    "        t = np.matrix(T_error[0:3,3]).T\n",
    "        abs_disp.append(np.sqrt( R**2. / 5 * np.trace(A.T * A) + (t + A*xc).T * (t + A*xc) ).item())\n",
    "        if prev_T!=None:\n",
    "            T_error = T.as_affine() - prev_T.as_affine() # - np.eye(4)\n",
    "            A = np.matrix(T_error[0:3,0:3])\n",
    "            t = np.matrix(T_error[0:3,3]).T\n",
    "            rel_disp.append(np.sqrt( R**2. / 5 * np.trace(A.T * A) + (t + A*xc).T * (t + A*xc) ).item())\n",
    "        else:\n",
    "            rel_disp.append(0.0)\n",
    "        prev_T = T\n",
    "    return aligned,np.array(abs_disp),np.array(rel_disp),np.array(transrot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_spikes(d, spike_thresh):\n",
    "    slice_mean = d.mean(axis=0).mean(axis=0)\n",
    "    t_z = (slice_mean - np.atleast_2d(slice_mean.mean(axis=1)).T) / np.atleast_2d(slice_mean.std(axis=1)).T\n",
    "    spikes = np.abs(t_z)>spike_thresh\n",
    "    spike_inds = np.transpose(spikes.nonzero())\n",
    "    # mask out the spikes and recompute z-scores using variance uncontaminated with spikes.\n",
    "    # This will catch smaller spikes that may have been swamped by big ones.\n",
    "    d.mask[:,:,spike_inds[:,0],spike_inds[:,1]] = True\n",
    "    slice_mean2 = d.mean(axis=0).mean(axis=0)\n",
    "    t_z = (slice_mean - np.atleast_2d(slice_mean.mean(axis=1)).T) / np.atleast_2d(slice_mean2.std(axis=1)).T\n",
    "    spikes = np.logical_or(spikes, np.abs(t_z)>spike_thresh)\n",
    "    spike_inds = np.transpose(spikes.nonzero())\n",
    "    return((spike_inds, t_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_qa(ni, tr, spike_thresh=6., nskip=4):\n",
    "    brain,good_vols = mask(ni.get_data(), nskip=nskip)\n",
    "    t = np.arange(0.,brain.shape[3]) * tr\n",
    "    # Get the global mean signal and subtract it out for spike detection\n",
    "    global_ts = brain.mean(0).mean(0).mean(0)\n",
    "    # Simple z-score-based spike detection\n",
    "    spike_inds,t_z = find_spikes(brain - global_ts, spike_thresh)\n",
    "    # Compute temporal snr on motion-corrected data,\n",
    "    aligned,abs_disp,rel_disp,transrot = estimate_motion(ni)\n",
    "    brain_aligned = np.ma.masked_array(aligned.get_data(), brain.mask)\n",
    "    # Remove slow-drift (3rd-order polynomial) from the variance\n",
    "    global_ts_aligned = brain_aligned.mean(0).mean(0).mean(0)\n",
    "    global_trend = np.poly1d(np.polyfit(t[good_vols], global_ts_aligned[good_vols], 3))(t)\n",
    "    tsnr = brain_aligned.mean(axis=3) / (brain_aligned - global_trend).std(axis=3)\n",
    "    # convert rotations to degrees\n",
    "    transrot[:,3:] *= 180./np.pi\n",
    "    return aligned,abs_disp,rel_disp,transrot, tsnr,global_ts,t_z,spike_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_figs(im_id, median_tsnr,aligned,abs_disp,rel_disp,transrot, tsnr,global_ts,t_z,spike_inds):\n",
    "    out_dir = im_id[:-7]\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "\n",
    "\n",
    "    #plot displacement\n",
    "    disp = pd.DataFrame({'Displacement (mm)':list(abs_disp) + list(rel_disp),\n",
    "                        'kind':['abs']*len(abs_disp)+['rel']*len(rel_disp),\n",
    "                       'time':range(len(abs_disp))*2,\n",
    "                       'subject':[0]*2*len(abs_disp)})\n",
    "    sns.tsplot(value = 'Displacement (mm)',time = 'time',unit = 'subject',condition = 'kind',data = disp)\n",
    "    out_f = out_dir + '/displacement.png'\n",
    "    plt.savefig(out_f)\n",
    "    plt.close()\n",
    "\n",
    "    #plot translations\n",
    "    trans = pd.DataFrame({'Translations (mm)':list(transrot[:,0]) + list(transrot[:,1]) + list(transrot[:,2]),\n",
    "                        'kind':['x']*len(abs_disp)+['y']*len(rel_disp)+['z']*len(rel_disp),\n",
    "                       'time':range(len(abs_disp))*3,\n",
    "                       'subject':[0]*3*len(abs_disp)})\n",
    "    sns.tsplot(value = 'Translations (mm)',time = 'time',unit = 'subject',condition = 'kind',data = trans)\n",
    "    out_f = out_dir + '/translations.png'\n",
    "    plt.savefig(out_f)\n",
    "    plt.close()\n",
    "\n",
    "    #plot rotations\n",
    "    transrot[:,3:] *= 180./np.pi\n",
    "    rot = pd.DataFrame({'Rotations (deg)':list(transrot[:,3]) + list(transrot[:,4]) + list(transrot[:,5]),\n",
    "                        'kind':['roll']*len(abs_disp)+['pitch']*len(rel_disp)+['yaw']*len(rel_disp),\n",
    "                       'time':range(len(abs_disp))*3,\n",
    "                       'subject':[0]*3*len(abs_disp)})\n",
    "    sns.tsplot(value = 'Rotations (deg)',time = 'time',unit = 'subject',condition = 'kind',data = rot)\n",
    "    out_f = out_dir + '/rotations.png'\n",
    "    plt.savefig(out_f)\n",
    "    plt.close()\n",
    "\n",
    "    #Plot signal intensity\n",
    "    ts = global_ts.data[np.logical_not(global_ts.mask)]\n",
    "    ts = scipy.stats.zscore(ts)\n",
    "    signal = pd.DataFrame({'Intensity (z)':ts, \n",
    "                           'unit': ['TR']*len(ts),\n",
    "                           'TR':range(len(ts))})\n",
    "    sns.tsplot(data = signal, value = 'Intensity (z)',time = 'TR',unit = 'unit')\n",
    "    out_f = out_dir + '/signal.png'\n",
    "    plt.title('TSNR = ' + str(median_tsnr))\n",
    "    plt.savefig(out_f)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_QA(im_id):\n",
    "    im = nb.load(im_id)\n",
    "    aligned,abs_disp,rel_disp,transrot, tsnr,global_ts,t_z,spike_inds = compute_qa(im, TR)\n",
    "    median_tsnr = np.ma.median(tsnr)\n",
    "    plot_figs(im_id,median_tsnr,aligned,abs_disp,rel_disp,transrot, tsnr,global_ts,t_z,spike_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "###Here you set the files you want to run and it will loop through###\n",
    "###You may need to adjust this a bit if the filenames have changed###\n",
    "#####################################################################\n",
    "home_dir = '/Users/ianballard/Dropbox/Decision Neuroscience Lab/fMRI_Data/Habitization/'\n",
    "subs= ['HAB02 Session 1','HAB03 Session 1']\n",
    "scans = map(str,range(1,7))\n",
    "files = [home_dir + sub + '/EPI' + scan + '.nii.gz' for scan in scans for sub in subs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing os on engine(s)\n",
      "importing numpy on engine(s)\n",
      "importing matplotlib on engine(s)\n",
      "importing glob from glob on engine(s)\n",
      "importing affine,Realign4d from nipy.algorithms.registration on engine(s)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "//anaconda/lib/python2.7/site-packages/skimage/filter/__init__.py:6: skimage_deprecation: The `skimage.filter` module has been renamed to `skimage.filters`.  This placeholder module will be removed in v0.13.\n",
      "  warn(skimage_deprecation('The `skimage.filter` module has been renamed '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "importing median_otsu from dipy.segment.mask on engine(s)\n",
      "importing sys on engine(s)\n",
      "importing json on engine(s)\n",
      "importing argparse on engine(s)\n",
      "importing time on engine(s)\n",
      "importing shutil on engine(s)\n",
      "importing nipype on engine(s)"
     ]
    }
   ],
   "source": [
    "dview = rc[0:3]\n",
    "dview.block = True\n",
    "\n",
    "dview.push(dict(home_dir = home_dir,\n",
    "                plot_figs = plot_figs,\n",
    "               compute_qa = compute_qa,\n",
    "               find_spikes = find_spikes,\n",
    "               mask = mask,\n",
    "               TR = TR,\n",
    "               estimate_motion = estimate_motion))\n",
    "dview.execute(\"import numpy as np\")\n",
    "dview.execute(\"import nibabel as nb\")\n",
    "dview.execute(\"import seaborn as sns\")\n",
    "dview.execute(\"import pandas as pd\")\n",
    "with dview.sync_imports():\n",
    "    import os\n",
    "    import numpy\n",
    "    import matplotlib\n",
    "    import os\n",
    "    from nipy.algorithms.registration import affine,Realign4d\n",
    "    from dipy.segment.mask import median_otsu\n",
    "    import sys\n",
    "    import scipy.stats\n",
    "dview.execute(\"%matplotlib inline\")\n",
    "dview.execute(\"import matplotlib.pyplot as plt\")\n",
    "dview.map_sync(run_QA,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
